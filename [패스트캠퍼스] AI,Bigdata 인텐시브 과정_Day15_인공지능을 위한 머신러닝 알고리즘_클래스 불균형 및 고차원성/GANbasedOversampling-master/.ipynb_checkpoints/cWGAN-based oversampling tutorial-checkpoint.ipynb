{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cat_dims\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WGANGP\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Samsung_edu_practice/GANbasedOversampling-master/helpers.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from dataloader import load_data\n",
    "from helpers import get_cat_dims\n",
    "\n",
    "from models import WGANGP\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "dataset = 'homeeq' # baesens et al. Home Equity\n",
    "\n",
    "# load data\n",
    "df, cat_cols, num_cols, target_col = load_data(dataset)\n",
    "X = df.loc[:, num_cols + cat_cols]\n",
    "y = df.loc[:, target_col]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2020)\n",
    "cat_dims = get_cat_dims(X_train, cat_cols)\n",
    "\n",
    "# preprocess data\n",
    "num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                         MinMaxScaler())\n",
    "cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                         OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "prep = ColumnTransformer([\n",
    "    ('num', num_prep, num_cols),\n",
    "    ('cat', cat_prep, cat_cols)],\n",
    "    remainder='drop')\n",
    "X_train_trans = prep.fit_transform(X_train)\n",
    "\n",
    "gan = WGANGP(write_to_disk=True, # whether to create an output folder. Plotting will be surpressed if flase\n",
    "            compute_metrics_every=1250, print_every=2500, plot_every=10000,\n",
    "            num_cols = num_cols, cat_dims=cat_dims,\n",
    "            # pass the one hot encoder to the GAN to enable count plots of categorical variables\n",
    "            transformer=prep.named_transformers_['cat']['onehotencoder'],\n",
    "            # pass column names to enable\n",
    "            cat_cols=cat_cols,\n",
    "            use_aux_classifier_loss=True,\n",
    "            d_updates_per_g=3, gp_weight=15)\n",
    "\n",
    "gan.fit(X_train_trans, y=y_train.values, \n",
    "        condition=True,\n",
    "        epochs=300,  \n",
    "        batch_size=64,\n",
    "        netG_kwargs = {'hidden_layer_sizes': (128,64), \n",
    "                        'n_cross_layers': 1,\n",
    "                        'cat_activation': 'gumbel_softmax',\n",
    "                        'num_activation': 'none',\n",
    "                        'condition_num_on_cat': True, \n",
    "                        'noise_dim': 30, \n",
    "                        'normal_noise': False,\n",
    "                        'activation':  'leaky_relu',\n",
    "                        'reduce_cat_dim': True,\n",
    "                        'use_num_hidden_layer': True,\n",
    "                        'layer_norm':False,},\n",
    "        netD_kwargs = {'hidden_layer_sizes': (128,64,32),\n",
    "                        'n_cross_layers': 2,\n",
    "                        'embedding_dims': 'auto',\n",
    "                        'activation':  'leaky_relu',\n",
    "                        'sigmoid_activation': False,\n",
    "                        'noisy_num_cols': True,\n",
    "                        'layer_norm':True,}\n",
    "       )\n",
    "\n",
    "X_res, y_res = gan.resample(X_train_trans, y=y_train)\n",
    "print(f'Original imbalance ratio was:{y_train.mean():.2f}\\nAfter resampling it is:{y_res.mean():.2f}')\n",
    "\n",
    "X_test_trans = prep.transform(X_test)\n",
    "clf = RandomForestClassifier(n_estimators=300, min_samples_leaf=1, max_features='sqrt', bootstrap=True,\n",
    "                             random_state=2020, n_jobs=2)\n",
    "\n",
    "clf.fit(X_res, y_res)\n",
    "preds_oversampled = clf.predict_proba(X_test_trans)[:,1]\n",
    "\n",
    "clf.fit(X_train_trans, y_train)\n",
    "preds_imbalanced = clf.predict_proba(X_test_trans)[:,1]\n",
    "\n",
    "print(f'AUC-ROC Random Forest:\\n'\n",
    "      f'Balanced data:\\t\\t{roc_auc_score(y_test, preds_oversampled):.4f}\\n'\n",
    "      f'Imbalanced data:\\t{roc_auc_score(y_test, preds_imbalanced):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp38-none-macosx_10_9_x86_64.whl (139.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.10.0-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/samsung/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/anaconda3/envs/samsung/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/samsung/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, filelock, torch\n",
      "Successfully installed filelock-3.10.0 mpmath-1.3.0 networkx-3.0 sympy-1.11.1 torch-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
