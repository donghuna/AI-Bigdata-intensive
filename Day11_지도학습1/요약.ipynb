{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning (Classification / Regression)\n",
    "\n",
    "- k-Nearest Neighbors (KNN)  \n",
    "- Linear Models  \n",
    "- Decision Trees  \n",
    "- Random Forests  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "k-Nearest Neighbors (KNN)  \n",
    "    - 새로운 data point에 대한 예측 시, dataset 내에서 가장 가까운 data point를 탐색  \n",
    "    - KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "* KNN의 Classification, Regression 차이점  \n",
    "    1. Dataset load, Data preprocessing은 동일  \n",
    "    2. Leaning : Classification은 KNeighborsClassifier, Regression은 KNeighborsRegressor  \n",
    "        - clf = KNeighborsClassifier(n_neighbors = 3)  \n",
    "        - reg = KNeighborsRegressor(n_neighbors=3)  \n",
    "  \n",
    "  \n",
    "Linear Models  \n",
    "    - 선형 함수로 값을 예측. 기존의 데이터셋을 기준으로 선하나 긋기  \n",
    "    1. LinearRegression : cost function을 최소화 하는 최적의 선\n",
    "    2. Ridge : L2 regularization 사용  \n",
    "    3. Lasso : L1 regularization 사용  \n",
    "    4. Logistic Regression : Binary classification에서 사용! class를 구분하는 경계를 긋는 것.  \n",
    "    - linear model은 binary classification에서만 사용가능하나 multi class classification으로 확장할수 있는 알고리즘도 존재하는듯?  \n",
    "\n",
    "Decision Trees  \n",
    "    - 땅 자르듯이, 계속 분할 하는 것\n",
    "    \n",
    "Random Forests  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (26, 2)\n",
      "shape of y (26,)\n",
      "y: [1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0.]\n",
      "ground truth of y_train: [0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "prediction result of y_train: [0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "ground truth of y_test: [1. 0. 1. 0. 1. 1. 0.]\n",
      "prediction result of y_test: [1. 0. 1. 0. 1. 0. 0.]\n",
      "train_accuracy: 0.9473684210526315\n",
      "test_accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dataset load - 'Forge Dataset'\n",
    "data = np.load('./data/forge_dataset.npy', allow_pickle=True)\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "print('shape of X:', X.shape)\n",
    "print('shape of y', y.shape)\n",
    "print('y:', y)\n",
    "\n",
    "# Data Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Learning\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = clf.predict(X_train_scaled)\n",
    "print('ground truth of y_train:', y_train)\n",
    "print('prediction result of y_train:', y_train_hat)\n",
    "\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "print('ground truth of y_test:', y_test)\n",
    "print('prediction result of y_test:', y_test_hat)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\t# classification accuracy\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "print('train_accuracy:', y_train_accuracy)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "print('test_accuracy:', y_test_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter  \n",
    "n_neighbors : 값이 작을수록 overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.944056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  train accuracy  test accuracy\n",
       "0  1        1.000000       0.916084\n",
       "1  3        0.957746       0.923077\n",
       "2  5        0.941315       0.937063\n",
       "3  7        0.938967       0.944056\n",
       "4  9        0.936620       0.958042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter search (number of neighbors)\n",
    "# \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer_dataset = load_breast_cancer()\n",
    "X, y = breast_cancer_dataset.data, breast_cancer_dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "k_search_list = range(1, 10, 2)\n",
    "\n",
    "for k in k_search_list:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_train_hat = clf.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "    y_test_hat = clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'k': k_search_list,\n",
    "    'train accuracy': train_accuracy_list,\n",
    "    'test accuracy': test_accuracy_list\n",
    "})\n",
    "display(result_df)  ## k 가 작을수록 overfitting 됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p  train accuracy  test accuracy\n",
       "0  1        0.957746       0.958042\n",
       "1  2        0.941315       0.937063\n",
       "2  3        0.941315       0.930070\n",
       "3  4        0.938967       0.930070\n",
       "4  5        0.938967       0.930070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter Search (Power parameter for Minkowski distance)\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "p_search_list = range(1,6)  \n",
    "# p = 1 : manhatten distance\n",
    "# p = 2 : euclidean distance\n",
    "# p >= 2 : minkowski distance\n",
    "\n",
    "for p in p_search_list:\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p=p)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_train_hat = clf.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "    y_test_hat = clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'p': p_search_list,\n",
    "    'train accuracy': train_accuracy_list,\n",
    "    'test accuracy': test_accuracy_list\n",
    "})\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (40, 1)\n",
      "shape of y (40,)\n",
      "y: [-0.44822073  0.33122576  0.77932073  0.03497884 -1.38773632 -2.47196233\n",
      " -1.52730805  1.49417157  1.00032374  0.22956153 -1.05979555  0.7789638\n",
      "  0.75418806 -1.51369739 -1.67303415 -0.90496988  0.08448544 -0.52734666\n",
      " -0.54114599 -0.3409073   0.21778193 -1.12469096  0.37299129  0.09756349\n",
      " -0.98618122  0.96695428 -1.13455014  0.69798591  0.43655826 -0.95652133\n",
      "  0.03527881 -2.08581717 -0.47411033  1.53708251  0.86893293  1.87664889\n",
      "  0.0945257  -1.41502356  0.25438895  0.09398858]\n",
      "ground truth of y_train: [-1.51369739 -2.47196233 -0.52734666 -1.67303415  1.53708251  1.49417157\n",
      " -0.47411033  0.33122576 -1.13455014  0.75418806 -2.08581717 -0.98618122\n",
      " -1.52730805  0.09756349 -1.12469096 -0.3409073   0.22956153  0.25438895\n",
      "  0.03497884 -0.44822073]\n",
      "prediction result of y_train: [-1.44042723 -1.89415682 -0.49284968 -1.63113382  1.12082662  1.26181405\n",
      " -1.04203645  1.12082662 -1.44042723  1.26181405 -2.07693788 -0.6539162\n",
      " -1.04203645 -0.23052151 -1.89415682 -0.5856804   0.17297644  0.17297644\n",
      " -0.07932629 -0.44561282]\n",
      "ground truth of y_test: [ 0.37299129  0.21778193  0.96695428 -1.38773632 -1.05979555 -0.90496988\n",
      "  0.43655826  0.7789638  -0.54114599 -0.95652133  0.69798591  1.87664889\n",
      " -1.41502356  0.77932073  0.09398858  0.03527881  0.86893293  0.08448544\n",
      "  0.0945257   1.00032374]\n",
      "prediction result of y_test: [-0.5856804  -0.07932629  0.82597372 -1.89415682 -1.04203645 -1.63113382\n",
      " -0.07932629  1.12082662 -0.44561282 -1.04203645 -0.49284968  0.82597372\n",
      " -1.04203645  0.41271285 -0.44561282 -0.07932629  1.12082662 -0.23052151\n",
      " -0.23052151 -0.07932629]\n",
      "train_MAE: 0.2985\n",
      "train_RMSE: 0.3870\n",
      "train_R_square: 0.8700\n",
      "test_MAE: 0.4646\n",
      "test_RMSE: 0.5807\n",
      "test_R_square: 0.5559\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dataset Load - 'Wave Dataset'\n",
    "data = np.load('./data/wave_dataset.npy', allow_pickle=True)\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "print('shape of X:', X.shape)\n",
    "print('shape of y', y.shape)\n",
    "print('y:', y)\n",
    "\n",
    "# Data Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Learning\n",
    "from sklearn.neighbors import KNeighborsRegressor   # KNN regression.\n",
    "reg = KNeighborsRegressor(n_neighbors=3)            # k = 3\n",
    "reg.fit(X_train_scaled, y_train)                    # fit (training)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = reg.predict(X_train_scaled)           # predict train data\n",
    "print('ground truth of y_train:', y_train)          # GT\n",
    "print('prediction result of y_train:', y_train_hat) # train result\n",
    "\n",
    "y_test_hat = reg.predict(X_test_scaled)             # predict test data\n",
    "print('ground truth of y_test:', y_test)            # GT\n",
    "print('prediction result of y_test:', y_test_hat)   # test result\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\t# regression accuracy\n",
    "\n",
    "y_train_mae = mean_absolute_error(y_train, y_train_hat)\n",
    "y_train_rmse = mean_squared_error(y_train, y_train_hat)**0.5\n",
    "y_train_r2 = r2_score(y_train, y_train_hat)\n",
    "print('train_MAE: %.4f'%y_train_mae)\n",
    "print('train_RMSE: %.4f'%y_train_rmse)\n",
    "print('train_R_square: %.4f'%y_train_r2)\n",
    "\n",
    "y_test_mae = mean_absolute_error(y_test, y_test_hat)\n",
    "y_test_rmse = mean_squared_error(y_test, y_test_hat)**0.5\n",
    "y_test_r2 = r2_score(y_test, y_test_hat)\n",
    "print('test_MAE: %.4f'%y_test_mae)\n",
    "print('test_RMSE: %.4f'%y_test_rmse)\n",
    "print('test_R_square: %.4f'%y_test_r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.56741\n",
      "train RMSE: 2.02246\n",
      "train R_square: 0.95205\n",
      "test MAE: 3.22590\n",
      "test RMSE: 5.66296\n",
      "test R_square: 0.60747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Dataset Load 'extended boston dataset'\n",
    "data = np.load('./data/extended_boston_dataset.npy', allow_pickle=True)\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "# print('shape of X:', X.shape)\n",
    "# print('shape of y', y.shape)\n",
    "# print('y:', y)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Learning\n",
    "reg_linear = LinearRegression()\n",
    "reg_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = reg_linear.predict(X_train_scaled)\n",
    "print('train MAE: %.5f'%mean_absolute_error(y_train, y_train_hat))\n",
    "print('train RMSE: %.5f'%mean_squared_error(y_train, y_train_hat)**0.5)\n",
    "print('train R_square: %.5f'%r2_score(y_train, y_train_hat))\n",
    "\n",
    "y_test_hat = reg_linear.predict(X_test_scaled)\n",
    "print('test MAE: %.5f'%mean_absolute_error(y_test, y_test_hat))\n",
    "print('test RMSE: %.5f'%mean_squared_error(y_test, y_test_hat)**0.5)\n",
    "print('test R_square: %.5f'%r2_score(y_test, y_test_hat))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.70581\n",
      "train RMSE: 2.30122\n",
      "train R_square: 0.93792\n",
      "test MAE: 2.81779\n",
      "test RMSE: 4.20133\n",
      "test R_square: 0.78395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Data load, data preprocessing은 위에서 처리\n",
    "\n",
    "# Learning (여기만 다름!!)\n",
    "reg_ridge = Ridge(alpha=1) # Hyperparameter alpha.\n",
    "reg_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Inference & Evaluation (LinearRegression와 동일)\n",
    "y_train_hat = reg_ridge.predict(X_train_scaled)\n",
    "print('train MAE: %.5f'%mean_absolute_error(y_train, y_train_hat))\n",
    "print('train RMSE: %.5f'%mean_squared_error(y_train, y_train_hat)**0.5)\n",
    "print('train R_square: %.5f'%r2_score(y_train, y_train_hat))\n",
    "\n",
    "y_test_hat = reg_ridge.predict(X_test_scaled)\n",
    "print('test MAE: %.5f'%mean_absolute_error(y_test, y_test_hat))\n",
    "print('test RMSE: %.5f'%mean_squared_error(y_test, y_test_hat)**0.5)\n",
    "print('test R_square: %.5f'%r2_score(y_test, y_test_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.70581\n",
      "train RMSE: 2.30122\n",
      "train R_square: 0.93792\n",
      "test MAE: 2.81779\n",
      "test RMSE: 4.20133\n",
      "test R_square: 0.78395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Data load, data preprocessing은 위에서 처리\n",
    "\n",
    "# Learning (여기만 다름!!)\n",
    "reg_lasso = Lasso(alpha=1)\n",
    "reg_lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Inference & Evaluation (LinearRegression와 동일)\n",
    "y_train_hat = reg_ridge.predict(X_train_scaled)\n",
    "print('train MAE: %.5f'%mean_absolute_error(y_train, y_train_hat))\n",
    "print('train RMSE: %.5f'%mean_squared_error(y_train, y_train_hat)**0.5)\n",
    "print('train R_square: %.5f'%r2_score(y_train, y_train_hat))\n",
    "\n",
    "y_test_hat = reg_ridge.predict(X_test_scaled)\n",
    "print('test MAE: %.5f'%mean_absolute_error(y_test, y_test_hat))\n",
    "print('test RMSE: %.5f'%mean_squared_error(y_test, y_test_hat)**0.5)\n",
    "print('test R_square: %.5f'%r2_score(y_test, y_test_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "데이터를 바꿔야되는데 왜?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth of y_train: [1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0\n",
      " 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1]\n",
      "prediction result of y_train: [1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0\n",
      " 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1]\n",
      "ground truth of y_test: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n",
      "prediction result of y_test: [0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0]\n",
      "train_accuracy: 0.9906103286384976\n",
      "test_accuracy: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data load\n",
    "breast_cancer_dataset = load_breast_cancer()\n",
    "X, y = breast_cancer_dataset.data, breast_cancer_dataset.target\n",
    "\n",
    "# print('shape of X:', X.shape)\n",
    "# print('shape of y', y.shape)\n",
    "# print('y:', y)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Learning\n",
    "clf = LogisticRegression(C=1)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = clf.predict(X_train_scaled)\n",
    "print('ground truth of y_train:', y_train)\n",
    "print('prediction result of y_train:', y_train_hat)\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "print('ground truth of y_test:', y_test)\n",
    "print('prediction result of y_test:', y_test_hat)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "print('train_accuracy:', y_train_accuracy)\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "print('test_accuracy:', y_test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 1.00000\n",
      "test_accuracy: 0.86713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset Load\n",
    "breast_cancer_dataset = load_breast_cancer()\n",
    "X, y = breast_cancer_dataset.data, breast_cancer_dataset.target\n",
    "\n",
    "# print('shape of X:', X.shape)\n",
    "# print('shape of y', y.shape)\n",
    "# print('y:', y)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n",
    "\n",
    "# Learning\n",
    "clf = DecisionTreeClassifier() # Hyperparameter (min_samples_leaf = m)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = clf.predict(X_train)\n",
    "print('train_accuracy: %.5f'%accuracy_score(y_train, y_train_hat))\n",
    "y_test_hat = clf.predict(X_test)\n",
    "print('test_accuracy: %.5f'%accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "# sklearn 내장함수로 tree 시각화 가능"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 1.00000\n",
      "test_accuracy: 0.97203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset Load\n",
    "breast_cancer_dataset = load_breast_cancer()\n",
    "X, y = breast_cancer_dataset.data, breast_cancer_dataset.target\n",
    "\n",
    "# print('shape of X:', X.shape)\n",
    "# print('shape of y', y.shape)\n",
    "# print('y:', y)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n",
    "\n",
    "# Learning\n",
    "clf = RandomForestClassifier() # Hyperparameter (n_estimators=n)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Inference & Evaluation\n",
    "y_train_hat = clf.predict(X_train)\n",
    "print('train_accuracy: %.5f'%accuracy_score(y_train, y_train_hat))\n",
    "y_test_hat = clf.predict(X_test)\n",
    "print('test_accuracy: %.5f'%accuracy_score(y_test, y_test_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung_dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50b03572ed4f909e3770f6ddcd2450a95adc4a202b81904878b542bec4d3ddf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
